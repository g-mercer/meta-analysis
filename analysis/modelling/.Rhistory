# library(metaAidR) only there for reference.
# import
extr_data <- read.csv("../../data_extraction/data_extraction_2x5.csv")
# remove > values for AI and formulation from df
extr_data_filt_ai <- extr_data [-grep(">", extr_data$AI_50), ]
extr_data_filt_ai_form <- extr_data_filt_ai [-grep(">", extr_data_filt_ai$FORM_50), ]
# make AI_50 and FORM_50 numeric
extr_data_filt_ai_form$AI_50 <- as.numeric(extr_data_filt_ai_form$AI_50)
extr_data_filt_ai_form$FORM_50 <- as.numeric(extr_data_filt_ai_form$FORM_50)
# make AI_ERROR_LOWER, AI_ERROR_HIGHER, FORM_ERROR_LOWER and FORM_ERROR_HIGHER numeric
extr_data_filt_ai_form$AI_ERROR_LOWER <- as.numeric(extr_data_filt_ai_form$AI_ERROR_LOWER)
extr_data_filt_ai_form$AI_ERROR_HIGHER <- as.numeric(extr_data_filt_ai_form$AI_ERROR_HIGHER)
extr_data_filt_ai_form$FORM_ERROR_LOWER <- as.numeric(extr_data_filt_ai_form$FORM_ERROR_LOWER)
extr_data_filt_ai_form$FORM_ERROR_HIGHER <- as.numeric(extr_data_filt_ai_form$FORM_ERROR_HIGHER)
# make AI_N_CONTAINER and AI_N_INDIVIDUALS_PER_CONTAINER numeric
extr_data_filt_ai_form$AI_N_CONTAINER <- as.numeric(extr_data_filt_ai_form$AI_N_CONTAINER)
extr_data_filt_ai_form$AI_N_INDIVIDUALS_PER_CONTAINER <- as.numeric(extr_data_filt_ai_form$AI_N_INDIVIDUALS_PER_CONTAINER)
# make FORM_N_CONTAINER and FORM_N_INDIVIDUALS_PER_CONTAINER numeric
extr_data_filt_ai_form$FORM_N_CONTAINER <- as.numeric(extr_data_filt_ai_form$FORM_N_CONTAINER)
extr_data_filt_ai_form$FORM_N_INDIVIDUALS_PER_CONTAINER <- as.numeric(extr_data_filt_ai_form$FORM_N_INDIVIDUALS_PER_CONTAINER)
# do the ai and formulations always both have ci_95 or se?
different_error_type <- extr_data_filt_ai_form [extr_data_filt_ai_form$AI_ERROR_TYPE != extr_data_filt_ai_form$FORM_ERROR_TYPE, ]
# remove these for now
extr_data_filt_ai_form <- extr_data_filt_ai_form [extr_data_filt_ai_form$AI_ERROR_TYPE == extr_data_filt_ai_form$FORM_ERROR_TYPE, ]
# keep just the CI_95 rows
ci_95_rows <- extr_data_filt_ai_form [extr_data_filt_ai_form$AI_ERROR_TYPE == "CI_95", ]
# SE values
SE_rows <- extr_data_filt_ai_form [extr_data_filt_ai_form$AI_ERROR_TYPE == "SE", ]
# for some CIs there were data inputting errors resulting in negative values for the arms.
# if either of the arms are greater than 0, retain
# row removed. This will be excluded from the analysis
ci_95_rows [(ci_95_rows$FORM_ERROR_LOWER <= 0) & (ci_95_rows$FORM_ERROR_HIGHER <= 0), ]
ci_95_rows <- ci_95_rows [(ci_95_rows$AI_ERROR_LOWER > 0) | (ci_95_rows$AI_ERROR_HIGHER > 0), ]
ci_95_rows <- ci_95_rows [(ci_95_rows$FORM_ERROR_LOWER > 0) | (ci_95_rows$FORM_ERROR_HIGHER > 0), ]
# missing variance df
missing_se <- extr_data [(extr_data$AI_ERROR_TYPE == "n/a") | (extr_data$FORM_ERROR_TYPE == "n/a"), ]
# save for exclusion_df
missing_se_excluded <-  missing_se [((missing_se$FORM_ERROR_LOWER <= 0) & (missing_se$FORM_ERROR_HIGHER <= 0)), ]
# remove the row where both CI arms were 0
missing_se <- missing_se [!((missing_se$FORM_ERROR_LOWER <= 0) & (missing_se$FORM_ERROR_HIGHER <= 0)), ]
# remove two effect sizes where CI was not generated in primary source due to reliability
missing_se <- missing_se [(missing_se$DATA_ID != "111") & (missing_se$DATA_ID != "370"), ]
# remove the > signs
missing_se$AI_50 <- gsub(">", "", missing_se$AI_50)
missing_se$FORM_50 <- gsub(">", "", missing_se$FORM_50)
# make AI_50 and FORM_50 numeric
missing_se$AI_50 <- as.numeric(missing_se$AI_50)
missing_se$FORM_50 <- as.numeric(missing_se$FORM_50)
# make AI_ERROR_LOWER, AI_ERROR_HIGHER, FORM_ERROR_LOWER and FORM_ERROR_HIGHER numeric
# NAs introduced by coercion but all this is, "n/a" being replaced by NA
missing_se$AI_ERROR_LOWER <- as.numeric(missing_se$AI_ERROR_LOWER)
missing_se$AI_ERROR_HIGHER <- as.numeric(missing_se$AI_ERROR_HIGHER)
missing_se$FORM_ERROR_LOWER <- as.numeric(missing_se$FORM_ERROR_LOWER)
missing_se$FORM_ERROR_HIGHER <- as.numeric(missing_se$FORM_ERROR_HIGHER)
# make AI_N_CONTAINER and AI_N_INDIVIDUALS_PER_CONTAINER numeric
missing_se$AI_N_CONTAINER <- as.numeric(missing_se$AI_N_CONTAINER)
missing_se$AI_N_INDIVIDUALS_PER_CONTAINER <- as.numeric(missing_se$AI_N_INDIVIDUALS_PER_CONTAINER)
# make FORM_N_CONTAINER and FORM_N_INDIVIDUALS_PER_CONTAINER numeric
missing_se$FORM_N_CONTAINER <- as.numeric(missing_se$FORM_N_CONTAINER)
missing_se$FORM_N_INDIVIDUALS_PER_CONTAINER <- as.numeric(missing_se$FORM_N_INDIVIDUALS_PER_CONTAINER)
nrow(missing_se [missing_se$AI_50 > missing_se$FORM_50, ])
nrow(missing_se [missing_se$AI_50 < missing_se$FORM_50, ])
nrow(missing_se [missing_se$AI_50 == missing_se$FORM_50, ])
nrow(missing_se [missing_se$AI_50 > missing_se$FORM_50, ]) / nrow(missing_se)
with_variance <- extr_data [(extr_data$AI_ERROR_TYPE != "n/a") & (extr_data$FORM_ERROR_TYPE != "n/a"), ]
# remove the row where both CI arms were 0
with_variance <- with_variance [!((with_variance$FORM_ERROR_LOWER <= 0) & (with_variance$FORM_ERROR_HIGHER <= 0)), ]
with_variance$AI_50 <- as.numeric(with_variance$AI_50)
with_variance$FORM_50 <- as.numeric(with_variance$FORM_50)
nrow(with_variance [with_variance$AI_50 > with_variance$FORM_50, ])
nrow(with_variance [with_variance$AI_50 < with_variance$FORM_50, ])
nrow(with_variance [with_variance$AI_50 == with_variance$FORM_50, ])
nrow(with_variance [with_variance$AI_50 > with_variance$FORM_50, ]) / nrow(with_variance)
# for effect sizes where CI was available, select the biggest arm
# for the AI
ci_95_rows$AI_BIGGEST_CI_ARM <- 0
for (i in 1:nrow(ci_95_rows)) {
if(ci_95_rows$AI_ERROR_LOWER [i] > ci_95_rows$AI_ERROR_HIGHER [i]) {
ci_95_rows$AI_BIGGEST_CI_ARM [i] <- ci_95_rows$AI_ERROR_LOWER [i]
}
else {
ci_95_rows$AI_BIGGEST_CI_ARM [i] <- ci_95_rows$AI_ERROR_HIGHER [i]
}
}
# calculate the individual sample size
# add a row for AI_N_INDIVIDUAL
ci_95_rows$AI_N_INDIVIDUAL <- ci_95_rows$AI_N_CONTAINER * ci_95_rows$AI_N_INDIVIDUALS_PER_CONTAINER
# SE calculated using sample size at the individual level.
ci_95_rows$AI_SE_INDIVIDUAL <- 0
for (i in 1:nrow(ci_95_rows)) {
ci_95_rows$AI_SE_INDIVIDUAL [i] <- ci_95_rows$AI_BIGGEST_CI_ARM [i] / -qt(.025, df = ci_95_rows$AI_N_INDIVIDUAL [i] -1)
}
# for the formulation
ci_95_rows$FORM_BIGGEST_CI_ARM <- 0
for (i in 1:nrow(ci_95_rows)) {
if(ci_95_rows$FORM_ERROR_LOWER [i] > ci_95_rows$FORM_ERROR_HIGHER [i]) {
ci_95_rows$FORM_BIGGEST_CI_ARM [i] <- ci_95_rows$FORM_ERROR_LOWER [i]
}
else {
ci_95_rows$FORM_BIGGEST_CI_ARM [i] <- ci_95_rows$FORM_ERROR_HIGHER [i]
}
}
# add a row for FORM_N_INDIVIDUAL
ci_95_rows$FORM_N_INDIVIDUAL <- ci_95_rows$FORM_N_CONTAINER * ci_95_rows$FORM_N_INDIVIDUALS_PER_CONTAINER
# SE calculated using sample size at the individual level.
ci_95_rows$FORM_SE_INDIVIDUAL <- 0
for (i in 1:nrow(ci_95_rows)) {
ci_95_rows$FORM_SE_INDIVIDUAL [i] <- ci_95_rows$FORM_BIGGEST_CI_ARM [i] / -qt(.025, df = ci_95_rows$FORM_N_INDIVIDUAL [i] -1)
}
SE_rows$AI_BIGGEST_CI_ARM <- NA
SE_rows$AI_N_INDIVIDUAL <- SE_rows$AI_N_CONTAINER * SE_rows$AI_N_INDIVIDUALS_PER_CONTAINER
SE_rows$AI_SE_INDIVIDUAL <- SE_rows$AI_ERROR_LOWER
SE_rows$FORM_BIGGEST_CI_ARM <- NA
SE_rows$FORM_N_INDIVIDUAL <- SE_rows$FORM_N_CONTAINER * SE_rows$FORM_N_INDIVIDUALS_PER_CONTAINER
SE_rows$FORM_SE_INDIVIDUAL <- SE_rows$FORM_ERROR_LOWER
# combine
CI_SE_combined <- rbind(ci_95_rows, SE_rows)
mixed_error_row <- different_error_type [1, ]
# AI expressed as SE
mixed_error_row$AI_BIGGEST_CI_ARM <- NA
mixed_error_row$AI_N_INDIVIDUAL <- mixed_error_row$AI_N_CONTAINER * mixed_error_row$AI_N_INDIVIDUALS_PER_CONTAINER
mixed_error_row$AI_SE_INDIVIDUAL <- mixed_error_row$AI_ERROR_LOWER
# FORM expressed as CI. Lower error larger of the two so just manually insert.
mixed_error_row$FORM_BIGGEST_CI_ARM <- NA
mixed_error_row$FORM_N_INDIVIDUAL <- mixed_error_row$FORM_N_CONTAINER * mixed_error_row$FORM_N_INDIVIDUALS_PER_CONTAINER
mixed_error_row$FORM_SE_INDIVIDUAL <- mixed_error_row$FORM_ERROR_LOWER / -qt(.025, df = mixed_error_row$FORM_N_INDIVIDUAL -1)
# combine
CI_SE_combined <- rbind(CI_SE_combined, mixed_error_row)
excluded_df <- different_error_type [2:3, ]
excluded_df$EXCLUSION_REASON <- "CIs could not be reliably generated in primary source"
excluded_df <- bind_rows(excluded_df,
extr_data_filt_ai_form [(extr_data_filt_ai_form$FORM_ERROR_LOWER <= 0) & (extr_data_filt_ai_form$FORM_ERROR_HIGHER <= 0), ])
excluded_df$EXCLUSION_REASON [3] <- "CI estimate was 0 for both arms"
# calculate LRR
CI_SE_combined$LRR <- log(CI_SE_combined$FORM_50/CI_SE_combined$AI_50)
# calculate LRR variance using var(lnRR) = SE_FORM^2/mean_FORM^2 + SE_AI^2/mean_AI^2
# individual SE variance
CI_SE_combined$LRR_VAR_INDIVIDUAL <- (CI_SE_combined$FORM_SE_INDIVIDUAL^2 / CI_SE_combined$FORM_50^2) + (CI_SE_combined$AI_SE_INDIVIDUAL^2 / CI_SE_combined$AI_50^2)
# for the AI calculate the SE where CIs are available
missing_se$AI_BIGGEST_CI_ARM <- NA
for (i in 1:nrow(missing_se)) {
if(!is.na(missing_se$AI_ERROR_LOWER [i])) {
if(missing_se$AI_ERROR_LOWER [i] > missing_se$AI_ERROR_HIGHER [i]) {
missing_se$AI_BIGGEST_CI_ARM [i] <- missing_se$AI_ERROR_LOWER [i]
}
else {
missing_se$AI_BIGGEST_CI_ARM [i] <- missing_se$AI_ERROR_HIGHER [i]
}
}
}
# add a row for AI_N_INDIVIDUAL
missing_se$AI_N_INDIVIDUAL <- missing_se$AI_N_CONTAINER * missing_se$AI_N_INDIVIDUALS_PER_CONTAINER
# SE calculated using sample size at the individual level.
missing_se$AI_SE_INDIVIDUAL <- NA
for (i in 1:nrow(missing_se)) {
if (!is.na(missing_se$AI_BIGGEST_CI_ARM [i])) {
missing_se$AI_SE_INDIVIDUAL [i] <- missing_se$AI_BIGGEST_CI_ARM [i] / -qt(.025, df = missing_se$AI_N_INDIVIDUAL [i] -1)
}
}
# for the formulation calculate the SE where CIs are available
missing_se$FORM_BIGGEST_CI_ARM <- NA
for (i in 1:nrow(missing_se)) {
if(!is.na(missing_se$FORM_ERROR_LOWER [i])) {
if(missing_se$FORM_ERROR_LOWER [i] > missing_se$FORM_ERROR_HIGHER [i]) {
missing_se$FORM_BIGGEST_CI_ARM [i] <- missing_se$FORM_ERROR_LOWER [i]
}
else {
missing_se$FORM_BIGGEST_CI_ARM [i] <- missing_se$FORM_ERROR_HIGHER [i]
}
}
}
# add a row for FORM_N_INDIVIDUAL
missing_se$FORM_N_INDIVIDUAL <- missing_se$FORM_N_CONTAINER * missing_se$FORM_N_INDIVIDUALS_PER_CONTAINER
# SE calculated using sample size at the individual level.
missing_se$FORM_SE_INDIVIDUAL <- NA
for (i in 1:nrow(missing_se)) {
if(!is.na(missing_se$FORM_BIGGEST_CI_ARM [i])) {
missing_se$FORM_SE_INDIVIDUAL [i] <- missing_se$FORM_BIGGEST_CI_ARM [i] / -qt(.025, df = missing_se$FORM_N_INDIVIDUAL [i] -1)
}
}
# calculate LRR
missing_se$LRR <- log(missing_se$FORM_50/missing_se$AI_50)
# calculate LRR variance using var(lnRR) = SE_FORM^2/mean_FORM^2 + SE_AI^2/mean_AI^2
# individual SE variance
missing_se$LRR_VAR_INDIVIDUAL <- (missing_se$FORM_SE_INDIVIDUAL^2 / missing_se$FORM_50^2) + (missing_se$AI_SE_INDIVIDUAL^2 / missing_se$AI_50^2)
# search missing_se for CIs where both arms are 0/negative.
missing_se [(missing_se$FORM_ERROR_LOWER <= 0) & (missing_se$FORM_ERROR_HIGHER <= 0) & !is.na(missing_se$FORM_ERROR_LOWER), ]
missing_se [(missing_se$AI_ERROR_LOWER <= 0) & (missing_se$AI_ERROR_HIGHER <= 0) & !is.na(missing_se$AI_ERROR_LOWER), ]
# add to exclusion dataframe
missing_se_excluded$EXCLUSION_REASON <- "both CI arms 0"
excluded_df <- rbind(excluded_df, missing_se_excluded)
full_dataset <- bind_rows(CI_SE_combined, missing_se)
# number of fungicide effect sizes in full dataset
nrow(full_dataset [full_dataset$PESTICIDE_CLASS == "fungicide",])
# number of algaecide effect sizes in full dataset
nrow(full_dataset [full_dataset$PESTICIDE_CLASS == "algaecide",])
tidy_up_fun <- function(variable) {
variable <- gsub("\\W+$", "", variable)
variable <- as.factor(variable)
}
# tidy up DATA_ID
full_dataset$DATA_ID <- as.factor(full_dataset$DATA_ID)
# tidy up STUDY_ID
full_dataset$STUDY_ID <- tidy_up_fun(variable = full_dataset$STUDY_ID)
# tidy up MULTIPLE_MEASUREMENT
full_dataset$MULTIPLE_MEASUREMENT <- tidy_up_fun(variable = full_dataset$MULTIPLE_MEASUREMENT)
# tidy up AI_NAME
full_dataset$AI_NAME <- tidy_up_fun(variable = full_dataset$AI_NAME)
# tidy up AI_ERROR_TYPE
full_dataset$AI_ERROR_TYPE <- tidy_up_fun(variable = full_dataset$AI_ERROR_TYPE)
# tidy up FORM_NAME
full_dataset$FORM_NAME <- tidy_up_fun(variable = full_dataset$FORM_NAME)
# tidy up FORM_ERROR_TYPE
full_dataset$FORM_ERROR_TYPE <- tidy_up_fun(variable = full_dataset$FORM_ERROR_TYPE)
# tidy up COMMON CONTROL
full_dataset$COMMON_CONTROL <- tidy_up_fun(variable = full_dataset$COMMON_CONTROL)
# tidy up SPECIES_NAME_BINOMIAL
# update names to modern names
full_dataset$SPECIES_NAME_BINOMIAL <- tidy_up_fun(variable = full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("^.*microb.*$", "Microbial community", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("R. clamitans", "Lithobates clamitans", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("R. pipiens", "Rana pipiens", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("R. catesbeiana", "Rana catesbeiana", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("H. chrysoscelis", "Hyla chrysoscelis", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("Vibrio fischeri", "Aliivibrio fischeri", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- gsub("B. fowleri", "Anaxyrus fowleri", full_dataset$SPECIES_NAME_BINOMIAL)
full_dataset$SPECIES_NAME_BINOMIAL <- tidy_up_fun(variable = full_dataset$SPECIES_NAME_BINOMIAL)
# tidy up SPECIES_CLASS
# update names to modern names
full_dataset$SPECIES_CLASS <- tidy_up_fun(variable = full_dataset$SPECIES_CLASS)
full_dataset$SPECIES_CLASS <- gsub("Collembola", "Entognatha", full_dataset$SPECIES_CLASS)
full_dataset$SPECIES_CLASS <- gsub("Teleostei", "Actinopterygii", full_dataset$SPECIES_CLASS)
full_dataset$SPECIES_CLASS <- gsub("Oligochaeta", "Clitellata", full_dataset$SPECIES_CLASS)
full_dataset$SPECIES_CLASS <- gsub("n/a", "Microbial community", full_dataset$SPECIES_CLASS)
full_dataset$SPECIES_CLASS <- tidy_up_fun(variable = full_dataset$SPECIES_CLASS)
# tidy up SPECIES_PHYLUM
full_dataset$SPECIES_PHYLUM <- tidy_up_fun(variable = full_dataset$SPECIES_PHYLUM)
full_dataset$SPECIES_PHYLUM <- gsub("n/a", "Microbial community", full_dataset$SPECIES_PHYLUM)
# different names for the same phylum
full_dataset$SPECIES_PHYLUM <- gsub("Pseudomonadota", "Proteobacteria", full_dataset$SPECIES_PHYLUM)
full_dataset$SPECIES_PHYLUM <- tidy_up_fun(variable = full_dataset$SPECIES_PHYLUM)
# tidy up SPECIES_KINGDOM
full_dataset$SPECIES_KINGDOM <- tidy_up_fun(variable = full_dataset$SPECIES_KINGDOM)
full_dataset$SPECIES_KINGDOM <- gsub("n/a", "Microbial community", full_dataset$SPECIES_KINGDOM)
full_dataset$SPECIES_KINGDOM <- gsub("Protozoa", "Chromista", full_dataset$SPECIES_KINGDOM)
full_dataset$SPECIES_KINGDOM <- tidy_up_fun(variable = full_dataset$SPECIES_KINGDOM)
# tidy up PESTICIDE_CLASS
full_dataset$PESTICIDE_CLASS <- tidy_up_fun(variable = full_dataset$PESTICIDE_CLASS)
full_dataset$PESTICIDE_CLASS <- gsub("bactericide/fungicide", "fungicide", full_dataset$PESTICIDE_CLASS)
full_dataset$PESTICIDE_CLASS <- tidy_up_fun(variable = full_dataset$PESTICIDE_CLASS)
# tidy up ECOSYSTEM
full_dataset$ECOSYSTEM <- tidy_up_fun(variable = full_dataset$ECOSYSTEM)
# tidy up EXPOSURE_ROUTE
full_dataset$EXPOSURE_ROUTE <- tidy_up_fun(variable = full_dataset$EXPOSURE_ROUTE)
full_dataset$EXPOSURE_ROUTE <- gsub("gavage", "oral-gavage", full_dataset$EXPOSURE_ROUTE)
full_dataset$EXPOSURE_ROUTE <- tidy_up_fun(variable = full_dataset$EXPOSURE_ROUTE)
# tidy up REGULATORY_STANDARDISED_GUIDELINES_FOLLOWED
full_dataset$REGULATORY_STANDARDISED_GUIDELINES_FOLLOWED <- tidy_up_fun(variable = full_dataset$REGULATORY_STANDARDISED_GUIDELINES_FOLLOWED)
# tidy up FORMULATION_TYPE
# make singular
full_dataset$FORMULATION_TYPE <- gsub("s$", "", full_dataset$FORMULATION_TYPE)
# lowercase
full_dataset$FORMULATION_TYPE <- tolower(full_dataset$FORMULATION_TYPE)
# factor
full_dataset$FORMULATION_TYPE <- as.factor(full_dataset$FORMULATION_TYPE)
# create a list where each element if a cluster of MULTIPLE_MEASUREMENT
mult_meas_cluster <- unique(full_dataset$MULTIPLE_MEASUREMENT)
cluster_list <- vector(mode='list', length=length(mult_meas_cluster))
for (i in 1:length(mult_meas_cluster)) {
for (j in 1:nrow(full_dataset)) {
if (mult_meas_cluster [i] == full_dataset$MULTIPLE_MEASUREMENT [j]) {
cluster_list [[i]] <- rbind(cluster_list [[i]], full_dataset [j, ])
}
}
}
# add t = 1:7 in each list element
for (i in 1:length(cluster_list)) {
cluster_list [[i]]$TIME_SIMPLE <- 0
for (j in 1:nrow(as.data.frame(cluster_list [i]))) {
cluster_list [[i]][j, colnames(cluster_list [[i]]) == "TIME_SIMPLE"] <- j
}
}
# turn back into df
library(tidyverse)
ED_50_data_simple_time <- tibble()
for (i in 1:length(cluster_list)) {
ED_50_data_simple_time <- rbind(ED_50_data_simple_time, cluster_list [[i]])
}
# ED_50_data_simple_time$TIME_SIMPLE to full_dataset according to DATA_ID
full_dataset$TIME_SIMPLE <- 0
for (i in 1:nrow(full_dataset)) {
for (j in 1:nrow(ED_50_data_simple_time)) {
if (full_dataset$DATA_ID [i] == ED_50_data_simple_time$DATA_ID [j]) {
full_dataset$TIME_SIMPLE [i] <- ED_50_data_simple_time$TIME_SIMPLE [j]
}
}
}
# reorder full_dataset
full_dataset <- full_dataset [, c(1,2,23,58,32,22,3:21,24:31,33:57)]
full_dataset_no_influential <- full_dataset [(full_dataset$DATA_ID != "409") & (full_dataset$DATA_ID != "410") , ]
influential_fung <- extr_data_filt_ai_form [(extr_data_filt_ai_form$DATA_ID == "409") | (extr_data_filt_ai_form$DATA_ID == "410") , ]
influential_fung$EXCLUSION_REASON <- "influential points for fungicide level"
# add to exclusion dataframe
excluded_df <- rbind(excluded_df, influential_fung)
# remove
full_dataset_no_influential_no_poor_primary_fit <- full_dataset_no_influential [(full_dataset_no_influential$AI_BIGGEST_CI_ARM < 10 * full_dataset_no_influential$AI_50) | (is.na(full_dataset_no_influential$AI_BIGGEST_CI_ARM)), ]
poor_primary_model_fit <- extr_data_filt_ai_form [(extr_data_filt_ai_form$DATA_ID == "258")
| (extr_data_filt_ai_form$DATA_ID == "259")
| (extr_data_filt_ai_form$DATA_ID == "270")
| (extr_data_filt_ai_form$DATA_ID == "320")
| (extr_data_filt_ai_form$DATA_ID == "328"), ]
poor_primary_model_fit$EXCLUSION_REASON <- "such wide CI arm in primary source that it indicates poor model fit"
# add to exclusion dataframe
excluded_df <- rbind(excluded_df, poor_primary_model_fit)
full_dataset_no_influential_no_poor_primary_fit_no_microbial <- full_dataset_no_influential_no_poor_primary_fit [full_dataset_no_influential_no_poor_primary_fit$SPECIES_NAME_BINOMIAL != "Microbial community", ]
# as this df name is cumbersume rename final_dataset_reduced.
# what is missing is track in excluded_df
full_dataset_reduced <- full_dataset_no_influential_no_poor_primary_fit_no_microbial
microbial <- extr_data_filt_ai_form [(extr_data_filt_ai_form$DATA_ID == "249") |
(extr_data_filt_ai_form$DATA_ID == "250") |
(extr_data_filt_ai_form$DATA_ID == "214") |
(extr_data_filt_ai_form$DATA_ID == "215") |
(extr_data_filt_ai_form$DATA_ID == "459"), ]
microbial$EXCLUSION_REASON <- "microbial community aggregates"
# add to exclusion dataframe
excluded_df <- rbind(excluded_df, microbial)
full_data_red_no_sim <- full_dataset_reduced [full_dataset_reduced$SE_SIMULATION_REQUIRED == "NO", ]
autocorrelation_matrix <- vcalc(vi = full_data_red_no_sim$LRR_VAR_INDIVIDUAL,
cluster = MULTIPLE_MEASUREMENT,
time1 = TIME_SIMPLE,
phi= 0.8,
data= full_data_red_no_sim)
# visualise the correlation
corrplot::corrplot(cov2cor(autocorrelation_matrix) [1:50, 1:50])
corrplot::corrplot(cov2cor(autocorrelation_matrix) [50:100, 50:100])
corrplot::corrplot(cov2cor(autocorrelation_matrix) [100:150, 100:150])
corrplot::corrplot(cov2cor(autocorrelation_matrix) [150:200, 150:200])
corrplot::corrplot(cov2cor(autocorrelation_matrix) [200:250, 200:250])
corrplot::corrplot(cov2cor(autocorrelation_matrix) [250:300, 250:300])
corrplot::corrplot(cov2cor(autocorrelation_matrix) [300:348, 300:348])
# order by multiple_measurement shows that the correlation structure is fine
# looks odd above because of the order I input it into the dataframe
structure_check <- full_data_red_no_sim [order(full_data_red_no_sim$MULTIPLE_MEASUREMENT), ]
structure_check_matrix <- vcalc(vi = structure_check$LRR_VAR_INDIVIDUAL,
cluster = MULTIPLE_MEASUREMENT,
time1 = TIME_SIMPLE,
phi= 0.8,
data= structure_check)
corrplot::corrplot(cov2cor(structure_check_matrix) [1:50, 1:50])
corrplot::corrplot(cov2cor(structure_check_matrix) [50:100, 50:100])
corrplot::corrplot(cov2cor(structure_check_matrix) [100:150, 100:150])
corrplot::corrplot(cov2cor(structure_check_matrix) [150:200, 150:200])
corrplot::corrplot(cov2cor(structure_check_matrix) [200:250, 200:250])
corrplot::corrplot(cov2cor(structure_check_matrix) [250:300, 250:300])
corrplot::corrplot(cov2cor(structure_check_matrix) [300:348, 300:348])
cairo_pdf("output/sampling_variance_correlation_150_200_plot.pdf")
corrplot::corrplot(cov2cor(structure_check_matrix) [150:200, 150:200])
dev.off()
vcalc_SE <- function (m, se, p1, data, cov_type = c("ROM", "LOR"))
{
cov_type <- match.arg(cov_type, choices = cov_type)
if (cov_type == "ROM") {
cov <- data[p1, se]^2/data[p1, m]^2
}
if (cov_type == "LOR") {
cov <- (1/data[p1, m] + 1)/(data[p1, n] - data[p1, m])
}
return(cov)
}
make_VCV_matrix_SE <- function (data, V, m, se, n, cluster, obs, type = c("vcv", "cor"),
vcal = c("none", "lnOR", "ROM"), rho = 0.5)
{
type <- match.arg(type, choices = type)
vcal <- match.arg(vcal, choices = vcal)
if (missing(data)) {
stop("Must specify dataframe via 'data' argument.")
}
if (missing(V)) {
stop("Must specify name of the variance variable via 'V' argument.")
}
if (missing(cluster)) {
stop("Must specify name of the clustering variable via 'cluster' argument.")
}
if (missing(obs)) {
obs <- 1:length(V)
}
if (missing(type)) {
type <- "vcv"
}
if (vcal != "none") {
if (missing(m) | missing(se)) {
stop("Must specify m and se arguments so that the covariance can be correctly calculated.")
}
}
new_matrix <- matrix(0, nrow = dim(data)[1], ncol = dim(data)[1])
rownames(new_matrix) <- data[, obs]
colnames(new_matrix) <- data[, obs]
tmp <- duplicated(data[, cluster])
shared_coord <- which(data[, cluster] %in% data[tmp, cluster] ==
TRUE)
combinations <- do.call("rbind", tapply(shared_coord, data[shared_coord,
cluster], function(x) t(utils::combn(x, 2))))
if (type == "vcv") {
for (i in 1:dim(combinations)[1]) {
p1 <- combinations[i, 1]
p2 <- combinations[i, 2]
if (vcal == "none") {
p1_p2_cov <- rho * sqrt(data[p1, V]) * sqrt(data[p2,
V])
}
else {
p1_p2_cov <- vcalc_SE(m, se, p1, data, cov_type = vcal)
}
new_matrix[p1, p2] <- p1_p2_cov
new_matrix[p2, p1] <- p1_p2_cov
}
diag(new_matrix) <- data[, V]
}
if (type == "cor") {
for (i in 1:dim(combinations)[1]) {
p1 <- combinations[i, 1]
p2 <- combinations[i, 2]
p1_p2_cov <- rho
new_matrix[p1, p2] <- p1_p2_cov
new_matrix[p2, p1] <- p1_p2_cov
}
diag(new_matrix) <- 1
}
return(new_matrix)
}
full_data_red_no_sim$obs <- 1:nrow(full_data_red_no_sim)
common_control_matrix <- make_VCV_matrix_SE(data = full_data_red_no_sim, V = "LRR_VAR_INDIVIDUAL", cluster = "COMMON_CONTROL", m = "AI_50",
se = "AI_SE_INDIVIDUAL", type = "vcv", vcal = "ROM", obs = "obs")
corrplot::corrplot(cov2cor(common_control_matrix) [1:50, 1:50])
corrplot::corrplot(cov2cor(common_control_matrix) [50:100, 50:100])
corrplot::corrplot(cov2cor(common_control_matrix) [100:150, 100:150])
corrplot::corrplot(cov2cor(common_control_matrix) [150:200, 150:200])
corrplot::corrplot(cov2cor(common_control_matrix) [200:250, 200:250])
corrplot::corrplot(cov2cor(common_control_matrix) [250:300, 250:300])
corrplot::corrplot(cov2cor(common_control_matrix) [300:348, 300:348])
taxa <- unique(as.character(full_data_red_no_sim$SPECIES_NAME_BINOMIAL))
# resolves names. A few of the names I had were older synonyms
resolved_names <- tnrs_match_names(taxa)
my_tree <- tol_induced_subtree(ott_ids = resolved_names$ott_id, label_format = "name")
plot(my_tree, type = "phylogram", cex = 0.3)
# add to df OTL species names
name_update <- cbind(unique(as.character(full_data_red_no_sim$SPECIES_NAME_BINOMIAL)), resolved_names$unique_name)
full_data_red_no_sim$SPECIES_NAME_BINOMIAL_OTL <- ""
for (i in 1:nrow(name_update)) {
for (j in 1:nrow(full_data_red_no_sim)) {
if (name_update [i, 1] == full_data_red_no_sim$SPECIES_NAME_BINOMIAL [j]) {
full_data_red_no_sim$SPECIES_NAME_BINOMIAL_OTL [j] <- name_update [i, 2]
}
}
}
# give updated names underscores to match species names in tree
full_data_red_no_sim$SPECIES_NAME_BINOMIAL_OTL <- gsub(" ", "_", full_data_red_no_sim$SPECIES_NAME_BINOMIAL_OTL)
tree_tip_label <- my_tree$tip.label
updated_species_list <- unique(full_data_red_no_sim$SPECIES_NAME_BINOMIAL_OTL)
# check if names from the raw data are not found in tree. Match up.
setdiff(tree_tip_label, updated_species_list)
library(ape)
# calculate branch lengths
my_tree <- ape::compute.brlen(my_tree, method = "Grafen", power = 1)
# use a randomization approach to deal with polytomies
my_tree <- ape::multi2di(my_tree, random = TRUE)
# create correlation matrix for analysis
phylo_cor <- vcv(my_tree, cor = T)
# save species tree
cairo_pdf("output/species_tree_plot.pdf")
plot(my_tree, type = "phylogram", cex = 0.3)
dev.off()
# with REML
final_model <- rma.mv(yi = LRR, V = autocorrelation_matrix,
mod = ~ 0 + PESTICIDE_CLASS,
random = list(~1 | STUDY_ID,
~ TIME_SIMPLE | MULTIPLE_MEASUREMENT),
struct = "AR",
data = full_data_red_no_sim, method = "REML", test = "t", dfs = "contain")
summary(final_model)
# RVE
robust(final_model, cluster = full_data_red_no_sim$STUDY_ID, clubSandwich = TRUE)
# PIs
mod_results(final_model, group = "STUDY_ID", mod = "PESTICIDE_CLASS")$mod_table
funnel(full_data_red_no_sim$LRR, full_data_red_no_sim$LRR_VAR_INDIVIDUAL, yaxis="seinv",
#xlim = c(-3, 3),
ylab = "Precision (1/SE)",
xlab = "Effect size (lnRR)")
# calculating "effective sample size" to account for unbalanced sampling, for lnRR
full_data_red_no_sim$E_N <- with(full_data_red_no_sim, (4*(AI_N_INDIVIDUAL*FORM_N_INDIVIDUAL)) / (AI_N_INDIVIDUAL + FORM_N_INDIVIDUAL))
# using effective sampling size
funnel(full_data_red_no_sim$LRR, full_data_red_no_sim$LRR_VAR_INDIVIDUAL, ni = full_data_red_no_sim$E_N, yaxis="ni",
#xlim = c(-3, 3),
ylab = "Effective sample size",
xlab = "Effect size (lnRR)")
# using effective sampling size just for herbicides
funnel(full_data_red_no_sim$LRR [full_data_red_no_sim$PESTICIDE_CLASS == "herbicide"],
full_data_red_no_sim$LRR_VAR_INDIVIDUAL [full_data_red_no_sim$PESTICIDE_CLASS == "herbicide"],
ni = full_data_red_no_sim$E_N [full_data_red_no_sim$PESTICIDE_CLASS == "herbicide"], yaxis="ni",
#xlim = c(-3, 3),
ylab = "Effective sample size",
xlab = "Effect size (lnRR)")
knitr::opts_chunk$set(echo = TRUE)
schmuck_dataset <- read.csv("input/schmuck_1994_dataset.csv")
# calculate median lnRR for each pesticide class
# herbicide
median(schmuck_dataset [schmuck_dataset$PESTICIDE_CLASS == "herbicide", ]$lnRR)
# insecticide
median(schmuck_dataset [schmuck_dataset$PESTICIDE_CLASS == "insecticide", ]$lnRR)
# fungicide
median(schmuck_dataset [schmuck_dataset$PESTICIDE_CLASS == "fungicide", ]$lnRR)
schmuck_dataset [schmuck_dataset$PESTICIDE_CLASS == "herbicide", ]
